# Monosemanticity on Quantized Models

<img width="522" alt="image" src="https://github.com/user-attachments/assets/f8627ddc-99e1-430a-8e1f-3e1f0db6a67f">



Forked from the https://github.com/neelnanda-io/1L-Sparse-Autoencoder repo with the following changes

1. Fixed errors in the script so that the training code works out of the box
2. Added experiments to see affect of quantization on monosemanticity and sparse autoencoder features.
3. Changes so that the .ipynb file to analyse features runs on generic models (and not just 1 layer)

